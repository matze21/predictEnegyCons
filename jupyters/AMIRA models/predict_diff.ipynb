{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import warnings\n",
    "\n",
    "# Suppress specific Intel MKL warnings\n",
    "warnings.filterwarnings(\"ignore\")#, category=DeprecationWarning, module=\"mkl\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA as ARIMA\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pd.read_csv(\"../../data/client.csv\")\n",
    "ePrices = pd.read_csv(\"../../data/electricity_prices.csv\")\n",
    "gasPrices = pd.read_csv(\"../../data/gas_prices.csv\")\n",
    "train = pd.read_csv(\"../../data/train.csv\")\n",
    "\n",
    "weatherPredInt = pd.read_csv(\"../model_architecture_study/interpolPredWeather.csv\")\n",
    "weatherHistInt = pd.read_csv(\"../histWeatherSnowCover.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1009176, 10)\n"
     ]
    }
   ],
   "source": [
    "producing = train.loc[train.is_consumption == 0]\n",
    "consuming = train.loc[train.is_consumption == 1]\n",
    "train = pd.merge(producing.drop('is_consumption',axis = 1), consuming.drop('is_consumption',axis = 1),on=['data_block_id','prediction_unit_id','datetime','county','is_business','product_type'], how='outer',suffixes=('_prod', '_cons'))\n",
    "del producing, consuming\n",
    "print(train.shape)\n",
    "\n",
    "clientsTime = pd.merge(train, client, on=['county','is_business','product_type','data_block_id'], how='inner')\n",
    "\n",
    "clientsTime['datetime'] = pd.to_datetime(clientsTime['datetime'])\n",
    "clientsTime['yearday'] = clientsTime['datetime'].dt.day_of_year\n",
    "clientsTime['weekday'] = clientsTime['datetime'].dt.day_of_week\n",
    "clientsTime['month'] = clientsTime['datetime'].dt.month\n",
    "clientsTime['monthday'] = clientsTime['datetime'].dt.day\n",
    "clientsTime['year'] = clientsTime['datetime'].dt.year\n",
    "clientsTime['hour'] = clientsTime['datetime'].dt.hour\n",
    "\n",
    "unique_pairs = list(set(zip(clientsTime['is_business'], clientsTime[ 'product_type'])))\n",
    "pair_index_dict = {pair: index for index, pair in enumerate(unique_pairs)}\n",
    "clientsTime['business_prodType'] = list(map(pair_index_dict.get, zip(clientsTime['is_business'], clientsTime['product_type'])))\n",
    "\n",
    "unique_pairs_cust = list(set(zip(clientsTime['is_business'], clientsTime[ 'product_type'], clientsTime['county'], clientsTime['eic_count'],clientsTime['installed_capacity'])))\n",
    "pair_index_dict = {pair: index for index, pair in enumerate(unique_pairs_cust)}\n",
    "clientsTime['ind_customer_id'] = list(map(pair_index_dict.get, zip(clientsTime['is_business'], clientsTime['product_type'], clientsTime['county'], clientsTime['eic_count'],clientsTime['installed_capacity'])))\n",
    "\n",
    "# interpolate daylight savings\n",
    "clientsTime = clientsTime.interpolate()\n",
    "\n",
    "\n",
    "import holidays\n",
    "from datetime import date\n",
    "\n",
    "us_holidays = holidays.EE()  # this is a dict\n",
    "\n",
    "clientsTime['holiday'] = clientsTime['datetime'].apply(lambda s : s in us_holidays)\n",
    "clientsTime['no_workday'] = ((clientsTime['holiday']) | (clientsTime['weekday'] > 4))\n",
    "\n",
    "ePrices['forecast_date'] = pd.to_datetime(ePrices['forecast_date'])\n",
    "ePrices['hour'] = ePrices.forecast_date.dt.hour\n",
    "# Set 'timestamp' as the index\n",
    "ePrices.set_index('forecast_date', inplace=True)\n",
    "\n",
    "# Resample to fill missing hours\n",
    "df_resampled = ePrices.resample('1H').asfreq()\n",
    "\n",
    "# Linearly interpolate missing values\n",
    "ePrices = df_resampled.interpolate(method='linear')\n",
    "\n",
    "ePrices['euros_per_mwh'] = ePrices.euros_per_mwh.replace(4000.0, np.nan)\n",
    "\n",
    "# Resample to fill missing hours\n",
    "df_resampled = ePrices.resample('1H').asfreq()\n",
    "\n",
    "# Linearly interpolate missing values\n",
    "ePrices = df_resampled.interpolate(method='linear')\n",
    "\n",
    "\n",
    "clientsTime2 = clientsTime.set_index(['datetime','prediction_unit_id'])\n",
    "clientsTime2 = pd.merge(clientsTime,ePrices[['data_block_id','hour','euros_per_mwh']], on=['data_block_id','hour'])#.set_index(['datetime','prediction_unit_id'])\n",
    "clientsTime2 = pd.merge(clientsTime2, gasPrices[['lowest_price_per_mwh','highest_price_per_mwh','data_block_id']], on=['data_block_id'])\n",
    "\n",
    "weatherPredInt['hour'] = weatherPredInt['hours_ahead'] - 24\n",
    "weatherPredInt['county'] = weatherPredInt['County']\n",
    "weatherPredInt.drop('County',axis = 1, inplace=True)\n",
    "weatherPredInt.drop('Unnamed: 0', axis = 1, inplace=True)\n",
    "weatherPredInt.set_index(['forecast_datetime','county'])\n",
    "clientsTime3 = pd.merge(clientsTime2, weatherPredInt, on=['county', 'hour','data_block_id'], how='inner', suffixes=('','_pred'))\n",
    "\n",
    "weatherHistInt['datetime'] = pd.to_datetime(weatherHistInt['datetime'])\n",
    "weatherHistInt['hour'] = weatherHistInt.datetime.dt.hour\n",
    "weatherHistInt['county'] = weatherHistInt['County']\n",
    "weatherHistInt.drop(['Unnamed: 0.1', 'Unnamed: 0','County'], axis = 1, inplace=True)\n",
    "\n",
    "#move hour timestamp 11 hours up and deal with proper time separation\n",
    "weatherHistInt['hour_original'] = weatherHistInt.datetime.dt.hour\n",
    "weatherHistInt['hour'] = weatherHistInt.datetime.dt.hour-11\n",
    "weatherHistInt['hour'] = weatherHistInt['hour'].apply(lambda s : s+24 if s<0 else s)\n",
    "\n",
    "weatherHistInt.loc[weatherHistInt.data_block_id == 3].hour.unique()\n",
    "mergedData = pd.merge(clientsTime3, weatherHistInt, on=['county', 'data_block_id', 'hour'], suffixes=('','_hist'))\n",
    "\n",
    "mergedData = mergedData.set_index(['ind_customer_id','datetime']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedData['old_target_prod'] = mergedData.groupby(['prediction_unit_id'])[['target_prod']].shift(48)\n",
    "mergedData['old_target_cons'] = mergedData.groupby(['prediction_unit_id'])[['target_cons']].shift(48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('predictenegycons')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "691b0b37d4acdba726dc1c278f9e08b3b5ec9c42dc9e0c737423aa652ed87f03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
